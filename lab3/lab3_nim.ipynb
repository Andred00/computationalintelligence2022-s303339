{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The player **taking the last object wins**.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab3` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n",
    "## Deadlines ([AoE](https://en.wikipedia.org/wiki/Anywhere_on_Earth))\n",
    "\n",
    "* Sunday, December 4th for Task3.1 and Task3.2\n",
    "* Sunday, December 11th for Task3.3 and Task3.4\n",
    "* Sunday, December 18th for all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate, chain\n",
    "from operator import xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1 - Fixed rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_rows_number(state: Nim) -> int: \n",
    "    return sum(o > 0 for o in state.rows)\n",
    "    \n",
    "# def pick_max_from_lowest(state: Nim) -> Nimply:\n",
    "#     \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "#     possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "#     return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n",
    "\n",
    "def pick_max_from_highest(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the highest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (m[0], m[1])))\n",
    "\n",
    "# def pick_min_from_lowest(state: Nim) -> Nimply:\n",
    "#     \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "#     possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "#     return Nimply(*min(possible_moves, key=lambda m: (m[0], m[1])))\n",
    "\n",
    "def pick_min_from_highest(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (m[0], -m[1])))\n",
    "\n",
    "def count_rows_and_choose(state: Nim) -> Nimply:\n",
    "    rows = active_rows_number(state)\n",
    "    if rows % 2 == 0:\n",
    "        return pick_min_from_highest(state)\n",
    "    else:\n",
    "        return pick_max_from_highest(state)\n",
    "\n",
    "def pick_odd_number_of_elements(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    ns = [n for n in range(1, state.rows[row]+1) if n%2!=0]\n",
    "    # print(ns)\n",
    "    num_objects = random.choice(ns)\n",
    "    return Nimply(row, num_objects)\n",
    "\n",
    "def pick_even_number_of_elements(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    if state.rows[row] == 1:\n",
    "        return Nimply(row, 1)\n",
    "    ns = [n for n in range(1, state.rows[row]+1) if n%2==0]\n",
    "    # print(ns)\n",
    "    num_objects = random.choice(ns)\n",
    "    return Nimply(row, num_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2 - Evolving agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_my_strategy(genome: dict) -> Callable:\n",
    "    def evolvable(state: Nim) -> Nimply:\n",
    "\n",
    "        if random.random() < genome[\"p\"]:\n",
    "            ply = count_rows_and_choose(state)\n",
    "        else:\n",
    "            ply = pure_random(state)\n",
    "            # if random.random() < genome[\"alfa\"]:\n",
    "            #     # pick max\n",
    "            #     if random.random() < genome[\"beta\"]:\n",
    "            #         # pick from highest\n",
    "            #         ply = pick_max_from_highest(state)\n",
    "            #     else:\n",
    "            #         ply = pick_max_from_lowest(state)\n",
    "            # else:\n",
    "            #     # pick min\n",
    "            #     if random.random() < genome[\"beta\"]:\n",
    "            #         # pick from highest\n",
    "            #         ply = pick_min_from_highest(state)\n",
    "            #     else:\n",
    "            #         ply = pick_min_from_lowest(state)\n",
    "\n",
    "        return ply\n",
    "\n",
    "    return evolvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_my_second_strategy(genome: dict) -> Callable:\n",
    "    def evolvable(state: Nim) -> Nimply:\n",
    "\n",
    "        if random.random() < genome[\"p\"]:\n",
    "            ply = pick_odd_number_of_elements(state)\n",
    "        else:\n",
    "            ply = pick_even_number_of_elements(state)\n",
    "        return ply\n",
    "\n",
    "    return evolvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_my_third_strategy(genome: dict) -> Callable:\n",
    "    def evolvable(state: Nim) -> Nimply:\n",
    "            \n",
    "        if random.random() < genome[\"p\"]:\n",
    "            return pick_min_from_highest(state)\n",
    "        else:\n",
    "            return pick_max_from_highest(state)\n",
    "    return evolvable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MATCHES = 100\n",
    "NIM_SIZE = 11\n",
    "\n",
    "\n",
    "def evaluate(strategy: Callable) -> float:\n",
    "    opponent = (strategy, pure_random)\n",
    "    # opponent = (pure_random, strategy)\n",
    "    won = 0\n",
    "\n",
    "    for m in range(NUM_MATCHES):\n",
    "        nim = Nim(NIM_SIZE)\n",
    "        player = 0\n",
    "        while nim:\n",
    "            ply = opponent[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 1:\n",
    "            won += 1\n",
    "    return won / NUM_MATCHES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to evolve\n",
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "Individual = namedtuple(\"Individual\",[\"genome\", \"fitness\"])\n",
    "POPULATION_SIZE = 100\n",
    "NUM_GENERATIONS = 101\n",
    "OFFSPRING_SIZE = 30\n",
    "MUT_RATE = 0.5\n",
    "\n",
    "def compute_fitness(genome, strategy):\n",
    "    return evaluate(strategy(genome))\n",
    "\n",
    "def tournament(population, tournament_size=2): \n",
    "    return max(random.choices(population, k=tournament_size), key=lambda i: i.fitness) \n",
    "\n",
    "def mutation(g):\n",
    "\n",
    "    if random.random() < 0.5:\n",
    "        g_mut = {\"p\": random.random()}\n",
    "    else:\n",
    "        g_mut = {\"p\": (g[\"p\"]+0.1)%1}\n",
    "    return g_mut\n",
    "\n",
    "def crossover(g1, g2):\n",
    "    p1 = g1[\"p\"]\n",
    "    p2 = g2[\"p\"]\n",
    "    p_cross = (p1+p2)/2\n",
    "    g_cross = {\"p\": p_cross}\n",
    "    return g_cross   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_genetic_algorithm(population, strategy):\n",
    "    for generation in range(NUM_GENERATIONS):\n",
    "        offspring = list()\n",
    "        for i in range(OFFSPRING_SIZE):\n",
    "            if random.random() < MUT_RATE:\n",
    "                p = tournament(population)\n",
    "                o = mutation(p.genome)\n",
    "            else:\n",
    "                p1 = tournament(population)                 # promising genome 1\n",
    "                p2 = tournament(population)                 # promising genome 2\n",
    "                o = crossover(p1.genome, p2.genome)\n",
    "            f = compute_fitness(o, strategy)\n",
    "            offspring.append(Individual(o,f))\n",
    "\n",
    "        population += offspring\n",
    "        population = sorted(population, key = lambda i: i.fitness, reverse=True)[:POPULATION_SIZE]\n",
    "\n",
    "        best_so_far = population[0]\n",
    "        if(generation % 10 == 0):\n",
    "            print(f\"GEN #{generation}\\tGENOME: {best_so_far.genome}\\tFITNESS: {best_so_far.fitness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population composed by randomic values\n",
    "def evolution(strategy):\n",
    "    population = list()\n",
    "    for _ in range(POPULATION_SIZE):\n",
    "        p = random.random()\n",
    "        genome = {\"p\": p}\n",
    "        population.append(Individual(genome, compute_fitness(genome, strategy)))\n",
    "\n",
    "    my_genetic_algorithm(population, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEN #0\tGENOME: {'p': 0.9906095959976272}\tFITNESS: 0.91\n",
      "GEN #10\tGENOME: {'p': 0.8232403523219204}\tFITNESS: 0.92\n",
      "GEN #20\tGENOME: {'p': 0.951564692045122}\tFITNESS: 0.93\n",
      "GEN #30\tGENOME: {'p': 0.951564692045122}\tFITNESS: 0.93\n",
      "GEN #40\tGENOME: {'p': 0.9722476272221032}\tFITNESS: 0.94\n",
      "GEN #50\tGENOME: {'p': 0.9722476272221032}\tFITNESS: 0.94\n",
      "GEN #60\tGENOME: {'p': 0.9722476272221032}\tFITNESS: 0.94\n",
      "GEN #70\tGENOME: {'p': 0.9722476272221032}\tFITNESS: 0.94\n",
      "GEN #80\tGENOME: {'p': 0.9722476272221032}\tFITNESS: 0.94\n",
      "GEN #90\tGENOME: {'p': 0.9722476272221032}\tFITNESS: 0.94\n",
      "GEN #100\tGENOME: {'p': 0.9722476272221032}\tFITNESS: 0.94\n"
     ]
    }
   ],
   "source": [
    "evolution(make_my_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEN #0\tGENOME: {'p': 0.6978118405831468}\tFITNESS: 0.62\n",
      "GEN #10\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #20\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #30\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #40\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #50\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #60\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #70\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #80\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #90\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n",
      "GEN #100\tGENOME: {'p': 0.13445811191091375}\tFITNESS: 0.69\n"
     ]
    }
   ],
   "source": [
    "evolution(make_my_second_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEN #0\tGENOME: {'p': 0.1790679923684113}\tFITNESS: 0.73\n",
      "GEN #10\tGENOME: {'p': 0.1790679923684113}\tFITNESS: 0.73\n",
      "GEN #20\tGENOME: {'p': 0.1790679923684113}\tFITNESS: 0.73\n",
      "GEN #30\tGENOME: {'p': 0.15001344805835132}\tFITNESS: 0.74\n",
      "GEN #40\tGENOME: {'p': 0.13123586696328393}\tFITNESS: 0.79\n",
      "GEN #50\tGENOME: {'p': 0.13123586696328393}\tFITNESS: 0.79\n",
      "GEN #60\tGENOME: {'p': 0.13123586696328393}\tFITNESS: 0.79\n",
      "GEN #70\tGENOME: {'p': 0.13123586696328393}\tFITNESS: 0.79\n",
      "GEN #80\tGENOME: {'p': 0.13123586696328393}\tFITNESS: 0.79\n",
      "GEN #90\tGENOME: {'p': 0.13123586696328393}\tFITNESS: 0.79\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [448], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evolution(make_my_third_strategy)\n",
      "Cell \u001b[1;32mIn [445], line 10\u001b[0m, in \u001b[0;36mevolution\u001b[1;34m(strategy)\u001b[0m\n\u001b[0;32m      7\u001b[0m     genome \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mp\u001b[39m\u001b[39m\"\u001b[39m: p}\n\u001b[0;32m      8\u001b[0m     population\u001b[39m.\u001b[39mappend(Individual(genome, compute_fitness(genome, strategy)))\n\u001b[1;32m---> 10\u001b[0m my_genetic_algorithm(population, strategy)\n",
      "Cell \u001b[1;32mIn [444], line 12\u001b[0m, in \u001b[0;36mmy_genetic_algorithm\u001b[1;34m(population, strategy)\u001b[0m\n\u001b[0;32m     10\u001b[0m         p2 \u001b[39m=\u001b[39m tournament(population)                 \u001b[39m# promising genome 2\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         o \u001b[39m=\u001b[39m crossover(p1\u001b[39m.\u001b[39mgenome, p2\u001b[39m.\u001b[39mgenome)\n\u001b[1;32m---> 12\u001b[0m     f \u001b[39m=\u001b[39m compute_fitness(o, strategy)\n\u001b[0;32m     13\u001b[0m     offspring\u001b[39m.\u001b[39mappend(Individual(o,f))\n\u001b[0;32m     15\u001b[0m population \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m offspring\n",
      "Cell \u001b[1;32mIn [443], line 8\u001b[0m, in \u001b[0;36mcompute_fitness\u001b[1;34m(genome, strategy)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_fitness\u001b[39m(genome, strategy):\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m evaluate(strategy(genome))\n",
      "Cell \u001b[1;32mIn [442], line 15\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(strategy)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mwhile\u001b[39;00m nim:\n\u001b[0;32m     14\u001b[0m     ply \u001b[39m=\u001b[39m opponent[player](nim)\n\u001b[1;32m---> 15\u001b[0m     nim\u001b[39m.\u001b[39;49mnimming(ply)\n\u001b[0;32m     16\u001b[0m     player \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m player\n\u001b[0;32m     17\u001b[0m \u001b[39mif\u001b[39;00m player \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "Cell \u001b[1;32mIn [436], line 22\u001b[0m, in \u001b[0;36mNim.nimming\u001b[1;34m(self, ply)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnimming\u001b[39m(\u001b[39mself\u001b[39m, ply: Nimply) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     row, num_objects \u001b[39m=\u001b[39m ply\n\u001b[1;32m---> 22\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rows[row] \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m num_objects\n\u001b[0;32m     23\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_k \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_objects \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_k\n\u001b[0;32m     24\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rows[row] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m num_objects\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evolution(make_my_third_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:status: Initial board  -> <1 3 5 7 9>\n",
      "DEBUG:root:status: After player 0 -> <1 3 5 7 0>\n",
      "DEBUG:root:status: After player 1 -> <1 3 5 6 0>\n",
      "DEBUG:root:status: After player 0 -> <1 3 5 5 0>\n",
      "DEBUG:root:status: After player 1 -> <1 3 5 4 0>\n",
      "DEBUG:root:status: After player 0 -> <1 3 5 3 0>\n",
      "DEBUG:root:status: After player 1 -> <1 3 5 2 0>\n",
      "DEBUG:root:status: After player 0 -> <1 3 5 1 0>\n",
      "DEBUG:root:status: After player 1 -> <1 3 5 0 0>\n",
      "DEBUG:root:status: After player 0 -> <1 3 0 0 0>\n",
      "DEBUG:root:status: After player 1 -> <1 2 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <1 1 0 0 0>\n",
      "DEBUG:root:status: After player 1 -> <1 0 0 0 0>\n",
      "DEBUG:root:status: After player 0 -> <0 0 0 0 0>\n",
      "INFO:root:status: Player 0 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "strategy = (count_rows_and_choose, pick_min_from_highest)\n",
    "\n",
    "nim = Nim(5)\n",
    "logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    nim.nimming(ply)\n",
    "    logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "logging.info(f\"status: Player {winner} won!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "385957ba4a504106e89afc93f22f38633e2124f079bb970f9afb051518064e80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
